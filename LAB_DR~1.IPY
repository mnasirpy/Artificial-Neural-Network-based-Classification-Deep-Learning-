{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0b9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small dataset laoding\n",
    "# Run when you want to run with SKlearn Digits dataset\n",
    "digits = load_digits()\n",
    "X=digits.data\n",
    "Y=digits.target\n",
    "\n",
    "#Split Dataset for ANN\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size= 0.3 , random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119fae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the MNIST dataset to be acceptable for the model\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((-1,784))/255.0\n",
    "x_test = x_test.reshape((-1,784))/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692efe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with MNist Dataset for other models\n",
    "X_train = x_train\n",
    "X_test  = x_test\n",
    "Y_train = y_train\n",
    "Y_test  = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de379578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784) (60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fdec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple ANN architecture (input layer=1, hidden layers=2, output layer=1)\n",
    "\n",
    "annmodel = Sequential([\n",
    "    \n",
    "    Dense(64, activation='relu',    # Hidden Layer-1\n",
    "          input_shape=(64,)),      # Input Layer # input_shape=(784,) and for sklear Digits input_shape=(64,)\n",
    "    #Dense(64, activation='relu'),  # Hidden Layer-2\n",
    "    #Dense(32, activation='relu'),   # Hidden Layer-3\n",
    "    Dense(10, activation='softmax') # Output Layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "annmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "S=time.time()\n",
    "annmodel.fit(x_train,y_train, batch_size=128, epochs=5, validation_data=(x_test, y_test))\n",
    "E= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e7c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "test_loss,  test_acc = annmodel.evaluate(x_test,y_test)\n",
    "#joblib.dump(cnnmodel, 'cnn_mdel.joblib')\n",
    "print(f\"Test Accuracy:\",{test_acc})\n",
    "print(f\"Total time taken while training\", E-S)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c312c9c",
   "metadata": {},
   "source": [
    "| ANN | Number of Hidden Layers | Batch-Size | Epochs | Training Accuracy | Test Accuracy |\n",
    "|-----|-------------------------|------------|--------|-------------------|---------------|\n",
    "|     | 3(128,64,32)            | 8          | 5      |   0.9772          | 0.9761        |\n",
    "|     | 3(64,64,32)             | 16         | 5      |   0.9808          | 0.9737        |\n",
    "|     | 2(64,32)                | 32         | 5      |   0.9798          | 0.9713        |\n",
    "|     | 2(128,64)               | 64         | 5      |   0.9848          | 0.9789        |\n",
    "|     | 1(32)                   | 128        | 5      |   0.9545          | 0.9511        | \n",
    "|     | 3(128,64,32)            | 128        | 5      |   0.9813          | 0.9725        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed8c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac84cb24",
   "metadata": {},
   "source": [
    "# Conclusion - Lab Task#1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f5d9ad8",
   "metadata": {},
   "source": [
    "When the Data is simple then Increasing the Batch-Size and Increasing the number of layers & Nuerons\n",
    "won't increase the accuracy of the Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b02b0",
   "metadata": {},
   "source": [
    "# Comparison Basic Machine Learning Models with ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b88644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X=digits.data\n",
    "Y=digits.target\n",
    "\n",
    "# Now with MNist Dataset\n",
    "# X_train = x_train\n",
    "# X_test  = x_test\n",
    "# Y_train = y_train\n",
    "# Y_test  = y_test\n",
    "\n",
    "#print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size= 0.3 , random_state=100)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size= 0.3 , random_state=100)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6639583",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a2cf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression  on training is : 0.9350666666666667\n",
      "Accuracy Score of Logistic Regression on testing data is : 0.9258\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_lr_train=lr.predict(X_train)\n",
    "\n",
    "acc_lr = accuracy_score(Y_test, y_pred_lr)\n",
    "acc_lr_train = accuracy_score(Y_train, y_pred_lr_train)\n",
    "\n",
    "print(f\"Accuracy Score of Logistic Regression  on training is : {acc_lr_train}\")\n",
    "print(f\"Accuracy Score of Logistic Regression on testing data is : {acc_lr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344c7c94",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c5d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Decision Tree on training is : 0.6722666666666667\n",
      "Accuracy Score of Decision Tree on Testing is : 0.6747\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "dtc.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "\n",
    "acc_dtc = accuracy_score(Y_test, y_pred_dtc)\n",
    "\n",
    "y_pred_dtc_train=dtc.predict(X_train)\n",
    "acc_dtc_train = accuracy_score(Y_train, y_pred_dtc_train)\n",
    "\n",
    "print(f\"Accuracy Score of Decision Tree on training is : {acc_dtc_train}\")\n",
    "print(f\"Accuracy Score of Decision Tree on Testing is : {acc_dtc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98efae8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_clf = RandomForestClassifier()\n",
    "rd_clf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_rd_clf = rd_clf.predict(X_test)\n",
    "acc_rd_clf = accuracy_score(Y_test, y_pred_rd_clf)\n",
    "\n",
    "y_pred_rd_clf_train = rd_clf.predict(X_train)\n",
    "acc_rd_clf_train = accuracy_score(Y_train, y_pred_rd_clf_train)\n",
    "\n",
    "\n",
    "print(f\"Accuracy Score of Decision Tree on training is : {acc_rd_clf_train}\")\n",
    "print(f\"Accuracy Score of Random Forest on Testing is : {acc_rd_clf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026934b",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b145ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNN(n_neighbors=5)\n",
    "# fit the model\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "acc_knn = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "acc_knn_train = accuracy_score(Y_train, y_pred_train)\n",
    "\n",
    "\n",
    "print(f\"Accuracy Score of KNN on training is : {acc_knn_train}\")\n",
    "print(f\"Accuracy Score of KNN on Testing is : {acc_knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d8056",
   "metadata": {},
   "outputs": [],
   "source": [
    "| Models              | Train Accuracy (Digits) | Test Accuracy (Digits)  | Train Accuracy (MNIST) | Test Accuracy (MNIST) |\n",
    "|---------------------|-------------------------|-------------------------|------------------------|-----------------------|\n",
    "| Logistic Regression | 1.0                     | 0.9759                  | 0.9351                 | 0.9258                |\n",
    "| Decision Tree       | 1.0                     | 0.85                    | 1.0                    | 0.8766                |\n",
    "| Random Forest       | 1.0                     | 0.85                    | 1.0                    | 0.9705                |\n",
    "| Naive Bayes (KNN)   | 0.9819                  | 0.9688                  | 0.9888                 | 0.9688                |\n",
    "| ANN                 | 0.9785                  | 0.9741                  | 0.9785                 | 0.9741                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9f758",
   "metadata": {},
   "source": [
    "# ANN with Sklearn Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "S=time.time()\n",
    "annmodel = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(64,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "annmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "annmodel.fit(X_train,Y_train,epochs=5,batch_size=128,validation_data=(X_test,Y_test))\n",
    "E=time.time()\n",
    "print(\"total time taken while training:\",E-S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298eadad",
   "metadata": {},
   "source": [
    "# Conclusion of Comparison of ANN with Other Machine Learning Models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f205033c",
   "metadata": {},
   "source": [
    "ANN gives better results in comparison with other models specially in large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3291b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
